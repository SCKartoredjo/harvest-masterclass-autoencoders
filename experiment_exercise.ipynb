{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T07:16:55.444670300Z",
     "start_time": "2023-06-16T07:16:45.500342800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = {\n",
    "0: \"T-shirt/top\",\n",
    "1: \"Trouser\",\n",
    "2: \"Pullover\",\n",
    "3: \"Dress\",\n",
    "4: \"Coat\",\n",
    "5: \"Sandal\",\n",
    "6: \"Shirt\",\n",
    "7: \"Sneaker\",\n",
    "8: \"Bag\",\n",
    "9: \"Ankle boot\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_test_cat(x_train: np.ndarray, x_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray, label=0) -> (np.ndarray, np.ndarray):\n",
    "    x_train = x_train[y_train == label]\n",
    "    x_test = x_test[y_test == label]\n",
    "    return x_train, x_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: get train data\n",
    "# 1\n",
    "##########################################################\n",
    "_, _ = get_train_test_cat(X_train, X_test, Y_train, Y_test, label=7) # Hint: het is wat er uit de functie komt\n",
    "##########################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# TODO: Init datascalar\n",
    "# 2\n",
    "############################################################\n",
    "scaler_in = MinMaxScaler()\n",
    "x_flat = ... # Hint: het is een vector, en de functie staat hieronder\n",
    "data_scaler = ... # Hint: sklearn gebruikt altijd fit\n",
    "#############################################################\n",
    "\n",
    "def unroll(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Maakt van de data een vector (samples, -1)\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.reshape(data, (len(data), -1))\n",
    "\n",
    "def add_dummy_dim(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Voegd een extra dummy dim to aan het eind\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.expand_dims(data, axis=-1)\n",
    "\n",
    "def norm_data(train: np.ndarray, test: np.ndarray, shape: str ='flat') -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Transformeerd data voor de autoencoder\n",
    "    flat: een vector\n",
    "    dummy: een extra dim aan het eind voor non compressie versie (is heel traag, gebruik deze niet)\n",
    "    None: Geeft de originele dims terug. Werkt prima, maar niet omdat het hoort. (Zie tensorflow docs voor meer informatie)\n",
    "    :param train:\n",
    "    :param test:\n",
    "    :param shape:\n",
    "    :return:\n",
    "    Genormaliseerde (eventueel getransformeerde) data\n",
    "    \"\"\"\n",
    "    unroll_train = unroll(train)\n",
    "    unroll_test = unroll(test)\n",
    "    _train = data_scaler.transform(unroll_train)\n",
    "    _test = data_scaler.transform(unroll_test)\n",
    "    if shape=='flat':\n",
    "        return _train, _test\n",
    "    if shape=='dummy':\n",
    "        return add_dummy_dim(train), add_dummy_dim(test)\n",
    "    else:\n",
    "        return np.reshape(_train, np.shape(train)), np.reshape(_test, np.shape(test))\n",
    "\n",
    "def reverse_data(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Geeft weer de orginele data terug. Is voornamelijk voor het plotten van de data.\n",
    "    In de tussentijd werk je alleen met de genormaliseerde data\n",
    "    :param data:\n",
    "    :return:\n",
    "    Inverse van de getransformeerde data\n",
    "    \"\"\"\n",
    "    if len(np.shape(data)) == 3:\n",
    "        flat = unroll(data)\n",
    "        inv_roll = data_scaler.inverse_transform(flat)\n",
    "        img = np.reshape(inv_roll, (len(data), np.shape(data)[1], np.shape(data)[2]))\n",
    "    elif len(np.shape(data)) == 4:\n",
    "        flat = np.squeeze(data)\n",
    "        inv_roll = data_scaler.inverse_transform(flat)\n",
    "        img = np.reshape(inv_roll, (len(data), np.shape(data)[1], np.shape(data)[2]))\n",
    "    else:\n",
    "        flat = data\n",
    "        inv_roll = data_scaler.inverse_transform(flat)\n",
    "        img = np.reshape(inv_roll, (len(data), int(np.sqrt(np.shape(data)[1])), int(np.sqrt(np.shape(data)[1]))))\n",
    "\n",
    "    return img\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: insert train set\n",
    "# 3\n",
    "####################################################\n",
    "_, _ = norm_data(..., ..., shape=\"flat\") # Hint: het is weer de train test set\n",
    "####################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "class AutoEncoder(Model):\n",
    "  def __init__(self, size_features):\n",
    "    super(AutoEncoder, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "                  # TODO: Maak hier je encoder\n",
    "                    # Hint: wat een encoder-decoder maakt is de vorm van het model. Deze moet een zandloper zijn. Het gaat werken met elke gare combi, maar dat is niet de bedoeling\n",
    "                    # Hint: de activate functies tussen layers is wat je zelf leuk vind. Gebruik bij twijfel altijd relu\n",
    "                    # Hint: tf.keras.layers.Dense(128, activation=\"relu\") is een layer\n",
    "                    # Hint: De layers moeten via een mapping van de ene naar de andere kunnen. Tensorflow snapt de meeste wel, maar een multiplicatie gaat altijd goed\n",
    "                    # Hint: Bv: 16 -> 8\n",
    "                    # Hint: Het is geen DNN, dus we hebben geen 50 layers nodig, kan natuurlijk wel, maar dan mag je ook een uur trainen haha\n",
    "                    # 4a\n",
    "                    #####################################################\n",
    "\n",
    "                    #####################################################\n",
    "              ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "                  # TODO: maak hier je decoder\n",
    "                    # Hint: De laatste layer moet een geleidelijke activatie (smooth) functie zijn. Kies de juiste\n",
    "                    # Hint: laatste layer moet ook de juiste aantal features bevatten\n",
    "                    # Hint: Er is een populaire phase function (beginnend met een s- eindigend op -oid) als laatste activatie function\n",
    "                    # 4b\n",
    "                    #####################################################\n",
    "\n",
    "                    #####################################################\n",
    "              ])\n",
    "  def call(self, x, **kwargs):\n",
    "    # TODO: Maak de call\n",
    "    # 4c\n",
    "    # Hint: het is letterlijk de naam van het model\n",
    "    # Hint: Negeer de kwargs, dat is voor tensorflow zelf\n",
    "    return ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: init het model met de hoeveelheid features van je train set\n",
    "# 5\n",
    "##############################################\n",
    "model = AutoEncoder(...) # Hint: bij een unroll/flat is het aantal features gelijk aan de lengte van de vector (aka het aantal pixels)\n",
    "#############################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: train het model\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, mode=\"min\")\n",
    "# 6\n",
    "####################################################################################################\n",
    "model.compile(optimizer='adam', loss=...) # Hint: het maakt niet uit\n",
    "history = model.fit(..., ..., epochs=200, batch_size=120, # Hint: Wat erin gaat moet er ook weer uit\n",
    "                    validation_data=(..., ...), # Hint: Je test set\n",
    "####################################################################################################\n",
    "                    shuffle=True,\n",
    "                    callbacks=[early_stopping]\n",
    "                   )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Tijd om je model te testen\n",
    "# 7\n",
    "###########################################\n",
    "pred = ... # Hint: er zijn 2 manieren: encode-decode OF gebruik de build in functie van tensorflow die altijd volgt na .fit\n",
    "###########################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: om weer bruikbare data te maken moeten we terug naar de echte waardes\n",
    "# 8\n",
    "################################################################################################\n",
    "pred_images = ... # Je moet de data omdraaien. De functie is al gemaakt. Als het goed is gegaan moet dit zonder aanpassingen gaan\n",
    "real_images = ... # Hint: Een set die je eerder gemaakt hebt\n",
    "################################################################################################\n",
    "# (extra hint in het geval iets niet werkt: Je moet misschien een squeeze uitvoeren)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optioneel: plot je data om te kijken of het goed is gegaan\n",
    "#################################################\n",
    "Image.fromarray(np.uint8(...))\n",
    "#################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_losses(train: np.ndarray, test: np.ndarray, y_labels: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Berekend alle losses van alle labels in de fashion MNIST set\n",
    "    :param train:\n",
    "    :param test:\n",
    "    :param y_labels:\n",
    "    :return:\n",
    "    Een dict met key: label en value: losses\n",
    "    \"\"\"\n",
    "    losses = dict()\n",
    "    for label, value in y_labels.items():\n",
    "        x_train, x_test = get_train_test_cat(X_train, X_test, Y_train, Y_test, label=label)\n",
    "        _, test = norm_data(x_train, x_test, shape=\"flat\")\n",
    "        losses[value] = tf.keras.losses.mse(model.predict(unroll(test)), unroll(test)).numpy()\n",
    "    return losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get losses van alle labels\n",
    "performance = get_losses(X_train, X_test, y_labels=labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: selecteer een threshold\n",
    "# 9\n",
    "###########################################################\n",
    "threshold = ... # Hint: loss van de ...\n",
    "############################################################\n",
    "# Hint: wat de threshold is maakt eigenlijk niet uit. Het is standaard om +/-2stdev te gebruiken oftewel ongeveer 5%. Maar dit hoeft niet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_detection(losses: np.ndarray, name:str, offset:float=0) -> None:\n",
    "    \"\"\"\n",
    "    Plot een histogram van alle losses en de threshold\n",
    "    :param losses:\n",
    "    :param name:\n",
    "    :param offset:\n",
    "    :return:\n",
    "    None (een print statement)\n",
    "    \"\"\"\n",
    "    sns.histplot(losses, bins=50)\n",
    "    _ = plt.axvline(threshold, color='r', linewidth=3, linestyle='dashed', label='{:0.3f}'.format(threshold))\n",
    "\n",
    "    passed = tf.math.less(losses, threshold+offset)\n",
    "    print(f\"Detection rate {name}: {100-tf.math.count_nonzero(passed).numpy()/len(losses)*100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, values in performance.items():\n",
    "    plot_detection(values, key, offset=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
